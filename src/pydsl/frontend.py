import ast
import ctypes
import dataclasses
import inspect
from inspect import BoundArguments
import logging
import re
import subprocess
import textwrap
import typing
from abc import ABC, abstractmethod
from ast import AST
from collections.abc import Callable, Iterator
from contextlib import contextmanager
from ctypes import POINTER, Structure, cdll
from functools import cache, singledispatch
from logging import info, warning
from pathlib import Path
from tempfile import NamedTemporaryFile, TemporaryDirectory, mkdtemp
from typing import (
    IO,
    Any,
    Optional,
    Protocol,
    Self,
    Type,
    Union,
    runtime_checkable,
)

from pydsl.compiler import CompilationError, Dialect, Module, Source, ToMLIR
from pydsl.func import Function
from pydsl.type import Tuple

import numpy as np

from pydsl.memref import DYNAMIC, MemRef
from pydsl.protocols import ArgContainer


def compose(funcs):
    def payload(x):
        y = x
        for f in funcs:
            y = f(y)

        return y

    return payload


CTypeTreeType: typing.TypeAlias = tuple[Union[type[Any], "CTypeTreeType"]]
CTypeTree: typing.TypeAlias = tuple[Union[Any, "CTypeTree"]]


@runtime_checkable
class SupportsCType(Protocol):
    @classmethod
    def CType(cls) -> CTypeTreeType:
        """
        Returns the class represented as a tuple tree of ctypes

        NOTE: Structures are not allowed. Represent them instead as a tuple.
        """
        ...

    @classmethod
    def to_CType(cls: type, arg_cont: ArgContainer, pyval: Any) -> CTypeTree:
        """
        Take a Python value and convert it to match the types of CType
        """
        ...

    @classmethod
    def from_CType(cls: type, arg_cont: ArgContainer, ct: CTypeTree) -> Any:
        """
        Take a tuple tree of ctypes value and convert it into a Python value
        """
        ...


@runtime_checkable
class SupportsPolyCType(Protocol):
    """
    Special case for Poly CTypes. Poly's CType convention is inconsistent with
    the LLVM convention.

    If this protocol is not specified, the regular SupportsCType should be
    used instead
    """

    @classmethod
    def PolyCType(cls) -> CTypeTreeType:
        """
        Returns the class represented as a tuple tree of ctypes

        NOTE: Structures are not allowed. Represent them instead as a tuple.
        """
        ...

    @classmethod
    def to_PolyCType(cls: type, pyval: Any) -> CTypeTree:
        """
        Take a Python value and convert it to match the types of CType
        """
        ...

    @classmethod
    def from_PolyCType(cls: type, ct: CTypeTree) -> Any:
        """
        Take a tuple tree of ctypes value and convert it into a Python value
        """
        ...


@cache
def CTypeTreeType_to_Structure(ct: CTypeTreeType) -> type[Structure] | Any:
    """
    Convert nested tuple tree of ctypes into a dynmaically-generated nested
    subclass of ctypes.Structure.

    If tuple or any child tuple is of length 1, return the ctype as-is without
    creating a Structure type at that node.
    """
    if not isinstance(ct, tuple):
        raise TypeError("ct is not a CTypeTreeType")

    # tuple is flattened if it's only one element
    if len(ct) == 1:
        return (
            CTypeTreeType_to_Structure(ct[0])
            if isinstance(ct[0], tuple)
            else ct[0]
        )

    # perform this operation recursively for all sub-tuples
    ct_recursive = [
        (CTypeTreeType_to_Structure(t) if isinstance(t, tuple) else t)
        for t in ct
    ]

    class AnonymousStructure(Structure):
        f"""
        This structure is dynamically generated by CTypeTreeType_to_Structure
        from {ct}
        """

    AnonymousStructure._fields_ = [
        (f"anonymous_field_{i}", t) for (i, t) in enumerate(ct_recursive)
    ]

    return AnonymousStructure


def CTypeTree_to_Structure(ct: CTypeTreeType, c: CTypeTree):
    """
    Convert nested tuple tree of ctypes and its corresponding tree of instances
    into an instance of a dynmaically-generated nested subclass of
    ctypes.Structure.

    If ct and c's structure don't correspond, an error is thrown.

    If tuple or any child tuple is of length 1, return the ctype as-is without
    creating a Structure type at that node.

    lambda x: CTypeTree_from_Structure(ct, x) o
    lambda x: CTypeTree_to_Structure(ct, x) should yield identity for all ct
    that is a tuple of size greater than 1 for inputs that corresponds to ct
    """
    # TODO: this function cannot yet capture cases where shape of the 2 trees
    # matches but the types don't

    if not (isinstance(ct, tuple) and isinstance(c, tuple)):
        raise TypeError(
            "CTypeTree and CTypeTreeType mismatch in terms of depth"
        )

    if not len(ct) == len(c):
        raise TypeError(
            "CTypeTree and CTypeTreeType mismatch in terms of length"
        )

    # tuple is flattened if it's only one element
    if len(ct) == 1:
        ret = (
            CTypeTree_to_Structure(ct[0], c[0])
            if (isinstance(ct[0], tuple) or isinstance(c[0], tuple))
            else c[0]
        )

        return ret

    c_recursive = [
        (
            CTypeTree_to_Structure(t, val)
            if (isinstance(t, tuple) or isinstance(val, tuple))
            else val
        )
        for t, val in zip(ct, c, strict=False)
    ]

    return CTypeTreeType_to_Structure(ct)(*c_recursive)


def CTypeTree_from_Structure(ct: CTypeTreeType, s: Structure) -> CTypeTree:
    """
    Take a structure and turn it back into tuple representation. The returned
    value will have the same tuple structure as ct.
    """

    if not isinstance(s, Structure):
        raise TypeError("s must be a Structure")

    if not isinstance(ct, tuple):
        raise TypeError("ct must be a CTypeTreeType")

    # this catches the edge case where CTypeTreeType has multiple nested tuple
    # we count the shells to be added back later and strip ct so we can
    # iterate the fields properly
    num_tuple_shell = 0
    while len(ct) == 1:
        num_tuple_shell += 1
        if isinstance(ct[0], tuple):
            ct = ct[0]

    if len(ct) != len(s._fields_):
        raise TypeError(
            f"length mismatch when converting back from Structure: expected"
            f"{ct}, got {len(s._fields_)}"
        )

    ret = []
    for t, (sname, st) in zip(ct, s._fields_, strict=False):
        num_member_tuple_shell = 0
        while isinstance(t, tuple) and len(t) == 1:
            num_member_tuple_shell += 1
            t = t[0]

        val = (
            CTypeTree_from_Structure(t, getattr(s, sname))
            if issubclass(st, Structure)
            else getattr(s, sname)
        )

        if (not issubclass(st, Structure)) and t != st:
            raise TypeError(
                f"type mismatch when converting back from Structure: expected"
                f"{t}, got {st}"
            )

        for _ in range(num_member_tuple_shell):
            val = (val,)

        ret.append(val)

    ret = tuple(ret)
    # re-add the tuple shells lost during the Structure conversion process
    for _ in range(num_tuple_shell):
        ret = (ret,)

    return tuple(ret)


T = typing.TypeVar("T")
CompilationPromise: typing.TypeAlias = Callable[["Module"], T]
DeliveredPromise: typing.TypeAlias = Callable[["CompilationTarget"], T]


class CompilationTarget(ABC):
    # class field
    _registered_promises: set[CompilationPromise] = set()

    # instance fields
    _module: Optional[Module] = None
    _promises: dict[CompilationPromise, Any]

    @property
    def get_module(self) -> Module:
        if self._module is None:
            raise RuntimeError(
                "compilation must be performed at least once before module "
                "can be accessed"
            )

        return self._module

    @classmethod
    def promise(cls: type["CompilationTarget"], f: CompilationPromise) -> None:
        """
        Annotation that indicates that a function that accepts a Module
        should have its result computed and cached within a CompilationTarget
        instance as soon as the visitor from that instance produces such
        output.

        This is necessary for computations that relies on the MLIR context
        scope before it is cleaned up.
        """

        cls._registered_promises.add(f)

        # this function is called to access a delivered promise
        def delivery(self: Self) -> Any:
            if self._module is None:
                raise RuntimeError(
                    f"compilation must be performed at least once before "
                    f"CompilationPromise {f.__name__} can be delivered"
                )
            return self._promises[f]

        setattr(cls, f.__name__, delivery)

    def initialize_instance_promises(self: Self) -> None:
        self._promises = {
            promise: None for promise in type(self)._registered_promises
        }

    def deliver_promises(self, out: Module):
        for f in self._promises.keys():
            self._promises[f] = f(out)

    def init_module(self) -> None:
        with self.compile() as out:
            self._module = out
            # promises must be delivered here as this is the only time
            # where we have access to MLIR's context
            self.deliver_promises(out)
            self.check_module_support()

    src: Source
    settings: "CompilationSetting"
    binpath: Path

    def __init__(
        self,
        src: Source,
        settings: "CompilationSetting",
    ):
        self.src = src
        self.settings = settings

        self.initialize_instance_promises()

        bin_prefix = "pydsl_bin_"

        # Due to TemporaryDirectory not having delete keyword param before 3.12
        # we have to use this very hacky solution
        bin: str = (
            # delete after process end
            TemporaryDirectory(prefix=bin_prefix).name
            if self.settings.clean_temp
            # doesn't delete after process end
            else mkdtemp(prefix=bin_prefix)
        )

        self.binpath = Path(bin)

        self.init_module()

        if self.settings.dump_mlir:
            print(self.emit_mlir())

        if self.settings.auto_build:
            self.build()

    @abstractmethod
    def compile(self) -> Iterator[Module]: ...

    @abstractmethod
    def build(self) -> None: ...

    @abstractmethod
    def call_function(self, fname, *args) -> Any: ...

    @abstractmethod
    def get_supported_dialects(self) -> set[Dialect]:
        """
        Returns the list of supported dialects as a set. Intended to be used
        by `check_module_support`.
        """
        ...

    def check_module_support(self) -> None:
        """
        This method checks over any aspect of `self` to see if the target
        is capable of compiling/running the generated MLIR module. If
        incapable, throws a `ValueError`.

        This is called after the MLIR module is generated.

        To get the module, call `self.get_module`.

        If not overridden, just checks whether each used dialect is in
        `self.get_supported_dialects`.
        """

        supported_dialects = self.get_supported_dialects()

        for d in self.dialects():
            if d not in supported_dialects:
                raise ValueError(
                    f"{d.name} dialect is not supported by "
                    f"{type(self).__qualname__}"
                )

    emit_mlir: DeliveredPromise[str]
    funcs: DeliveredPromise[dict[str, Function]]
    dialects: DeliveredPromise[set[Dialect]]


@CompilationTarget.promise
def emit_mlir(out: Module) -> str:
    return str(out.mlir)


@CompilationTarget.promise
def funcs(out: Module) -> dict[str, Function]:
    fs = out.functions
    return {f.name: f for f in fs}


@CompilationTarget.promise
def dialects(out: Module) -> set[Dialect]:
    return out.dialects


class CTarget(CompilationTarget):
    _so: NamedTemporaryFile
    flag_print_all_passes = "-mlir-print-ir-before-all"

    @property
    def _flags(self: Self) -> list[str]:
        transform_passes = (
            ["-transform-interpreter"]
            if self.settings.transform_seq is not None
            else []
        )
        # copy-before-write disables one-shot-bufferize from making
        # optimizations. Can be useful for debugging.
        one_shot_bufferize = [
            # "copy-before-write",
            "allow-unknown-ops",
            "bufferize-function-boundaries",
        ]
        return [
            *transform_passes,
            "-eliminate-empty-tensors",
            "-empty-tensor-to-alloc-tensor",
            f"-one-shot-bufferize='{' '.join(one_shot_bufferize)}'",
            "-canonicalize",
            "-buffer-deallocation",
            "-convert-bufferization-to-memref",
            "-convert-linalg-to-loops",
            "-cse",
            "-expand-strided-metadata",
            "-lower-affine",
            "-convert-scf-to-cf",
            "-convert-index-to-llvm",
            "-convert-math-to-llvm",
            "-arith-expand",
            "-finalize-memref-to-llvm",
            # TODO: it's not a good idea to reveal C wrapper for
            # private functions.
            "-llvm-request-c-wrappers",
            "-convert-math-to-libm",
            "-convert-func-to-llvm",
            # Only necessary for LLVM 20
            # "-convert-arith-to-llvm",
            # "-convert-cf-to-llvm",
            "-reconcile-unrealized-casts",
            "-test-transform-dialect-erase-schedule",
            "-cse",
        ]

    def cmds_to_str(self, cmds) -> str:
        return " ".join([str(c) for c in cmds])

    def log_command_result(self, cmds, result) -> None:
        if result.stderr:
            warning(
                f"""The following warning/error is caused by this command:
{self.cmds_to_str(cmds)}
{"*" * 20}
{result.stderr.decode("utf-8")}{"*" * 20}
"""
            )
        else:
            info(
                f"""The following command ran without issues:
{self.cmds_to_str(cmds)}
"""
            )

    def run_and_get_output(self, cmds):
        result = subprocess.run(
            self.cmds_to_str(cmds),
            capture_output=True,
            shell=True,
            check=False,
        )
        self.log_command_result(cmds, result)
        result.check_returncode()
        return result.stdout.decode("utf-8") if result.stdout else None

    def run_and_pipe_output(self, cmds, stdout: IO):
        result = subprocess.run(
            self.cmds_to_str(cmds),
            stdout=stdout,
            stderr=subprocess.PIPE,
            shell=True,
            check=False,
        )
        self.log_command_result(cmds, result)
        result.check_returncode()
        return result.stdout.decode("utf-8") if result.stdout else None

    def check_cmd(self, cmd: str) -> None:
        ...
        # TODO something should be done to ensure that the command exists at
        # all, and should use logging.info to inform which executable is being
        # used

    def mlir_passes(
        self, src: Path, flags, cmd="mlir-opt"
    ) -> NamedTemporaryFile:
        file = NamedTemporaryFile(
            dir=self.binpath, suffix=".mlir", delete=False
        )

        if self.settings.dump_mlir_passes:
            flags.append(self.flag_print_all_passes)

        self.run_and_pipe_output([cmd, *flags, src], file)

        return file

    def mlir_to_ll(
        self, src: Path, cmd="mlir-translate"
    ) -> NamedTemporaryFile:
        file = NamedTemporaryFile(dir=self.binpath, suffix=".ll", delete=False)
        self.run_and_get_output([
            cmd,
            "--mlir-to-llvmir",
            src,
            "-o",
            file.name,
        ])

        if self.settings.dump_llvmir:
            print(file.read().decode("utf8"))

        return file

    def ll_to_so(self, src: Path, cmd="clang") -> NamedTemporaryFile:
        file = NamedTemporaryFile(dir=self.binpath, suffix=".so", delete=False)
        self.run_and_get_output([
            cmd,
            "-O3",
            "-shared",
            "-Wno-override-module",  # suppress target override warnings
            src,
            "-o",
            file.name,
            "-L$PYDSL_LLVM/lib",
            "-Wl,-rpath=$PYDSL_LLVM/lib",
            "-lmlir_c_runner_utils",
        ])

        return file

    @cache
    def load_function(self, f: Function):
        ret_struct: type[Structure] | type = CTypeTreeType_to_Structure(
            self.get_return_ctypes(f)
        )
        # all structs are passed by pointer
        if issubclass(ret_struct, Structure):
            ret_struct = POINTER(ret_struct)

        args_struct: list[type[Structure] | type] = [
            CTypeTreeType_to_Structure(t) for t in self.get_args_ctypes(f)
        ]
        # all structs are passed by pointer
        args_struct = [
            POINTER(t) if issubclass(t, Structure) else t for t in args_struct
        ]

        """
        Manage LLVM C-wrapper calling convention.

        When -llvm-request-c-wrappers gets passed or the function has the unit
        attribute `llvm.emit_c_interface` prior to -convert-func-to-llvm, the
        lowering process:
        - Will create another version of the function with the name
          prepended with `_mlir_ciface_`.
        - All types that are represented in a composite manner, such as MemRef
          or complex types, will be passed into the function through struct
          pointers.
        - If the return type of the function is "composite" in any way, such as
          -> (i32, i32) or -> memref<?x?xi16>, the wrapper function will have
          void return type. Instead of returning the return value directly, it
          writes the return value to the first argument passed into the
          function as a struct pointer.

        Example: If the return type is (i32, memref<?x?xi16>), then when it's
        lowered, the first argument will be expected to be a !llvm.ptr where
        the return type is written to as !llvm.struct<(i32, struct<(ptr, ptr,
        i64, array<2 x i64>, array<2 x i64>)>)>. The function itself is void.

        See more info here:
        https://mlir.llvm.org/docs/TargetLLVMIR/#c-compatible-wrapper-emission
        """

        loaded_so = cdll.LoadLibrary(self._so.name)
        so_f = getattr(  # TODO: this may throw an error
            loaded_so, f"_mlir_ciface_{f.name}"
        )

        if self.has_composite_return(f):
            so_f.restype = None  # void function
            args_struct.insert(0, ret_struct)  # instead write to first arg
        else:
            so_f.restype = ret_struct

        so_f.argtypes = tuple(args_struct)

        return so_f

    def get_func(self: Self, fname: str) -> Function:
        if fname in (fns := self.funcs()):
            return fns[fname]

        raise ValueError(f"{fname} cannot be found as a callable function")

    def get_return_ctypes(self, f: Function) -> CTypeTreeType:
        """
        Given a function, returns how its value would get returned in
        CTypeTreeType format.

        The returned outermost tuple have either length 0 or 1:
        - 0 corresponds to None, i.e. a unit type.
        - 1 corresponds to a single return type.

        No representation exists for bottom type as the function would never
        return.

        More than 1 return is not allowed, as those kind of returns
        should be encoded as a Tuple[...], which is then 1 return.

        Examples:
        - None                  ↦ ()
        - UInt32                ↦ ((ctype.c_uint32,),)
        - Tuple[()]             ↦ ((),)
        - Tuple[UInt32,]        ↦ (((ctype.c_uint32,),),)
        - Tuple[UInt32, UInt32] ↦ (((ctype.c_uint32,), (ctype.c_uint32,)),)
        """
        ret_t = f.signature.return_annotation

        match ret_t:
            case None | inspect.Signature.empty:
                # Outermost length is 0
                return ()
            case _:
                # Outermost length is 1
                return (self.type_to_CType(ret_t),)

    # TODO: move to Function instead
    @cache
    def get_args_ctypes(self, f: Function) -> CTypeTreeType:
        sig = f.signature
        args_t = [sig.parameters[key].annotation for key in sig.parameters]

        if not all([isinstance(t, SupportsCType) for t in args_t]):
            raise TypeError(
                f"argument types {args_t} of {f.name} cannot be converted "
                f"into ctypes. Not all elements implement SupportsCType"
            )

        return tuple(self.type_to_CType(t) for t in args_t)

    def has_composite_return(self, f: Function) -> bool:
        def flatten_tuple(tup):
            if not isinstance(tup, tuple):
                return (tup,)

            return sum([flatten_tuple(t) for t in tup], ())

        flattened = flatten_tuple(self.get_return_ctypes(f))
        return len(flattened) > 1

    def has_void_return(self, f: Function) -> bool:
        return len(self.get_return_ctypes(f)) == 0

    @classmethod
    def type_to_CType(cls, typ: SupportsCType) -> CTypeTreeType:
        return typ.CType()

    @classmethod
    def val_to_CType(
        cls, arg_cont: ArgContainer, typ: SupportsCType, val: Any
    ) -> CTypeTree:
        return typ.to_CType(arg_cont, val)

    @classmethod
    def val_from_CType(
        cls, arg_cont: ArgContainer, typ: SupportsCType, val: CTypeTree
    ):
        match val:
            case ():
                # Outermost length is 0
                return None
            case (val_sub,):
                # Outermost length is 1
                return typ.from_CType(arg_cont, val_sub)
            case _:
                raise ValueError("CType val must be a tuple of size 0 or 1")

    def get_transform_source(self) -> Optional[AST]:
        return (
            ast.parse(
                textwrap.dedent(inspect.getsource(self.settings.transform_seq))
            )
            if self.settings.transform_seq is not None
            else None
        )

    @contextmanager
    def compile(self: Self) -> Iterator[Module]:
        to_mlir = ToMLIR(
            self.settings.locals,
            catch_comp_error=self.settings.catch_comp_error,
        )

        try:
            with to_mlir.compile(
                self.src.src_ast, transform_seq=self.get_transform_source()
            ) as out:
                self.out = out
                yield out

        except CompilationError as ce:
            # add source info and raise it further up the call stack
            ce.src = self.src
            raise ce

    def build(self) -> None:
        mlir = self.emit_mlir()

        file = NamedTemporaryFile(dir=self.binpath, suffix=".mlir")

        with open(file.name, "w") as f:
            f.write(mlir)

        def temp_file_to_path(tempf):
            return Path(tempf.name)

        self._so = compose([
            temp_file_to_path,
            lambda path: self.mlir_passes(path, self._flags),
            temp_file_to_path,
            self.mlir_to_ll,
            temp_file_to_path,
            self.ll_to_so,
        ])(file)

    def parse_args(self, signature, *args, **kwargs) -> BoundArguments:
        """
        Try to bind arguments, apply defaults, and type cast. Arguments should
        already be compiled to PyDSL types by this point.
        """
        params = signature.parameters

        try:
            # Associate each argument value passed into the call with
            # the parameter of the function
            bound_args = signature.bind(*args, **kwargs)
            binding = bound_args.arguments
        except TypeError as e:
            raise TypeError(
                f"couldn't bind arguments when calling an inline function: {e}"
            ) from e

        # Apply defaults for unfilled arguments
        bound_args.apply_defaults()

        return bound_args

    # TODO: this function is too large. Should break it down a bit
    def call_function(self, fname: str, *args, **kwargs) -> Any:
        if not hasattr(self, "_so"):
            raise RuntimeError(
                f"function {fname} is called before it is compiled"
            )

        f = self.get_func(fname)
        sig = f.signature
        so_f = self.load_function(f)
        if not len(sig.parameters) == len(args) + len(kwargs):
            raise TypeError(
                f"{f.name} takes {len(sig.parameters)} "
                f"argument{'s' if len(sig.parameters) > 1 else ''} "
                f"but {len(args) + len(kwargs)} were given"
            )

        arg_cont = ArgContainer()

        bound_args = self.parse_args(sig, *args, **kwargs)

        mapped_args_ct = [
            (
                ct,
                self.val_to_CType(arg_cont, sig.parameters[key].annotation, a),
            )
            for ct, (key, a) in zip(
                self.get_args_ctypes(f),
                bound_args.arguments.items(),
                strict=False,
            )
        ]

        mapped_args = [CTypeTree_to_Structure(*i) for i in mapped_args_ct]

        if self.has_void_return(f):
            so_f(*mapped_args)  # Call function
            return None

        if not self.has_composite_return(f):
            retval = so_f(*mapped_args)  # Call function

            # This double tuple construct is essential!
            # - The outermost tuple tells us that the return is not void
            # - The inner tuple formats the returned element in the same
            #   way as a composite struct
            # See docstring of get_return_ctypes for detail
            retval_ct = ((retval,),)

            # This is a necessary compensation as MLIR lowering confuses
            # single-element tuples with actual single elements, which
            # is why single-element tuples do not get considered by MLIR
            # as a composite return.
            # This confusion exists at the MLIR builtin language level and
            # there's nothing we can do about it.
            if issubclass(f.return_type, Tuple):
                retval_ct = (retval_ct,)

            return self.val_from_CType(arg_cont, f.return_type, retval_ct)

        # instantiate a structure return type, which by LLVM calling
        # convention is a void function that writes the return value in-place
        # to the first argument
        retval = CTypeTreeType_to_Structure(self.get_return_ctypes(f))()
        mapped_args.insert(0, retval)

        so_f(*mapped_args)  # Call function

        # the result is written in-place to retval. Convert it back to Python
        # CTypes
        retval_ct = CTypeTree_from_Structure(self.get_return_ctypes(f), retval)

        return self.val_from_CType(arg_cont, f.return_type, retval_ct)

    def get_supported_dialects(self) -> set[Dialect]:
        # NOTE: `transform` does NOT include `transform.validator` dialect
        return {
            Dialect.from_name("affine"),
            Dialect.from_name("arith"),
            Dialect.from_name("bufferization"),
            Dialect.from_name("builtin"),
            Dialect.from_name("cf"),
            Dialect.from_name("func"),
            Dialect.from_name("index"),
            Dialect.from_name("linalg"),
            Dialect.from_name("llvm"),
            Dialect.from_name("math"),
            Dialect.from_name("memref"),
            Dialect.from_name("mesh"),
            Dialect.from_name("scf"),
            Dialect.from_name("tensor"),
            Dialect.from_name("transform"),
            Dialect.from_name("transform.loop"),
            Dialect.from_name("transform.structured"),
        }


class PolyCTarget(CTarget):
    """
    Subclasses CTarget. Basically the same behavior with a few exceptions.

    - Different compilation pipeline
    - Use Poly calling convention. If that's not defined, use the typical LLVM
    C calling convention.
    - Transform sequence is not ignored.
    """

    # This flag is different on mlir-affine-validator
    flag_print_all_passes = "-validator-print-after-all"

    @classmethod
    def type_to_CType(
        cls, typ: Type[SupportsPolyCType] | Type[SupportsCType]
    ) -> tuple[type]:
        if hasattr(typ, "PolyCType"):
            return typ.PolyCType()

        return typ.CType()

    @classmethod
    def val_to_CType(
        cls, typ: SupportsPolyCType | SupportsCType, val: Any
    ) -> tuple[type]:
        if hasattr(typ, "to_PolyCType"):
            return typ.to_PolyCType(val)

        return typ.to_CType(val)

    @classmethod
    def val_from_CType(
        cls, typ: SupportsPolyCType | SupportsCType, val: Any
    ) -> tuple[type]:
        match val:
            case ():
                # Outermost length is 0
                return None
            case (val_sub,):
                # Outermost length is 1
                if hasattr(typ, "from_PolyCType"):
                    return typ.from_PolyCType(val_sub)

                return typ.from_CType(val_sub)
            case _:
                raise ValueError("CType val must be a tuple of size 0 or 1")

    @cache
    def get_args_ctypes(self, f: Function) -> CTypeTreeType:
        sig = f.signature
        args_t = [sig.parameters[key].annotation for key in sig.parameters]

        if not all([
            isinstance(t, SupportsCType) or isinstance(t, SupportsPolyCType)
            for t in args_t
        ]):
            raise TypeError(
                f"argument types {f.return_type} of {f.name} cannot be "
                "converted into ctypes. Not all elements implement "
                "SupportsCType"
            )

        return tuple(self.type_to_CType(t) for t in args_t)

    @contextmanager
    def compile(self) -> Iterator[Module]:
        to_mlir = ToMLIR(
            self.settings.locals,
            catch_comp_error=self.settings.catch_comp_error,
        )

        try:
            with to_mlir.compile(
                self.src.src_ast, transform_seq=self.get_transform_source()
            ) as out:
                self.out = out
                yield out

        except CompilationError as ce:
            # Add source info and raise it further up the call stack
            ce.src = self.src
            raise ce

    def build(self) -> None:
        mlir = self.emit_mlir()
        mlir_file = NamedTemporaryFile(
            dir=self.binpath, suffix=".mlir", delete=False
        )
        with open(mlir_file.name, "w") as f:
            f.write(mlir)

        affine_validator_mlir_file = NamedTemporaryFile(
            dir=self.binpath, suffix=".mlir", delete=False
        )
        c_file = NamedTemporaryFile(
            dir=self.binpath, suffix=".c", delete=False
        )

        self.run_and_get_output([
            "mlir-affine-validator",
            mlir_file.name,
            "-no-thread-local=1",
            f"-output {affine_validator_mlir_file.name}",
            "--codegen-output",
            c_file.name,
        ])

        so_file = NamedTemporaryFile(
            dir=self.binpath, suffix=".so", delete=False
        )
        self.run_and_get_output([
            "clang",
            "-O3",
            "-DPOLYBENCH_TIME",
            "-DDATA_TYPE_IS_FLOAT",
            # "../utilities/polybench.c",
            f"-D{self.settings.dataset}",
            "-fopenmp",
            "-I/usr/lib/gcc/aarch64-linux-gnu/9/include/",
            "-lomp",
            "-fPIC",
            # "-I../utilities/",
            "-I.",
            c_file.name,
            "-shared",
            "-o",
            so_file.name,
        ])

        self._so = so_file

    @cache
    def load_function(self, f: Function):
        ret_struct: type[Structure] | type = CTypeTreeType_to_Structure(
            self.get_return_ctypes(f)
        )
        # All structs are passed by pointer
        if issubclass(ret_struct, Structure):
            ret_struct = POINTER(ret_struct)

        args_struct: list[type[Structure] | type] = [
            CTypeTreeType_to_Structure(t) for t in self.get_args_ctypes(f)
        ]
        # All structs are passed by pointer
        args_struct = [
            POINTER(t) if issubclass(t, Structure) else t for t in args_struct
        ]

        """
        Manage LLVM C-wrapper calling convention.

        When -llvm-request-c-wrappers gets passed or the function has the unit
        attribute `llvm.emit_c_interface` prior to -convert-func-to-llvm, the
        lowering process:
        - Will create another version of the function with the name
          prepended with `_mlir_ciface_`.
        - All types that are represented in a composite manner, such as MemRef
          or complex types, will be passed into the function through struct
          pointers.
        - If the return type of the function is "composite" in any way, such as
          -> (i32, i32) or -> memref<?x?xi16>, the wrapper function will have
          void return type. Instead of returning the return value directly, it
          writes the return value to the first argument passed into the
          function as a struct pointer.

        Example: If the return type is (i32, memref<?x?xi16>), then when it's
        lowered, the first argument will be expected to be a !llvm.ptr where
        the return type is written to as !llvm.struct<(i32, struct<(ptr, ptr,
        i64, array<2 x i64>, array<2 x i64>)>)>. The function itself is void.

        See more info here:
        https://mlir.llvm.org/docs/TargetLLVMIR/#c-compatible-wrapper-emission
        """

        loaded_so = cdll.LoadLibrary(self._so.name)
        so_f = getattr(loaded_so, f.name)  # TODO: this may throw an error

        if self.has_composite_return(f):
            so_f.restype = None  # void function
            args_struct.insert(0, ret_struct)  # instead write to first arg
        else:
            so_f.restype = ret_struct

        so_f.argtypes = tuple(args_struct)

        return so_f

    def call_function(self, fname: str, *args) -> Any:
        if self.has_composite_return(self.get_func(fname)):
            raise RuntimeError(
                f"PolyCTarget cannot call {fname} because it has "
                f"composite return type"
            )

        if not hasattr(self, "_so"):
            raise RuntimeError(
                f"function {fname} is called before it is compiled"
            )

        f = self.get_func(fname)
        sig = f.signature
        so_f = self.load_function(f)
        if not len(sig.parameters) == len(args):
            raise TypeError(
                f"{f.name} takes {len(sig.parameters)} positional "
                f"argument{'s' if len(sig.parameters) > 1 else ''} "
                f"but {len(args)} were given"
            )

        # This is a bit of a hack that should get cleaned up later
        # Kevin had some ideas about how to best do that
        mapped_args_ct = []

        for ct, param, a in zip(
            self.get_args_ctypes(f),
            sig.parameters.values(),
            args,
            strict=False,
        ):
            if issubclass(param.annotation, MemRef) and (
                DYNAMIC in param.annotation.shape
            ):
                # polybench requires dynamic memrefs to have their stries passed
                # in as arguments
                a: np.ndarray
                _, aligned_ptr, _, _, strides = (
                    param.annotation._ndarray_to_CType(a)
                )
                mapped_args_ct.append(((ctypes.c_void_p,), (aligned_ptr,)))
                for i in range(len(param.annotation.shape)):
                    mapped_args_ct.append(((ctypes.c_int,), (strides[i],)))
            else:
                mapped_args_ct.append((
                    ct,
                    self.val_to_CType(param.annotation, a),
                ))

        mapped_args = [CTypeTree_to_Structure(*i) for i in mapped_args_ct]

        if self.has_void_return(f):
            so_f(*mapped_args)  # Call function
            return None

        if not self.has_composite_return(f):
            retval = so_f(*mapped_args)  # Call function

            # This double tuple construct is essential!
            # - The outermost tuple tells us that the return is not void
            # - The inner tuple formats the returned element in the same
            #   way as a composite struct
            # See docstring of get_return_ctypes for detail
            retval_ct = ((retval,),)  # Call function

            # This is a necessary compensation as MLIR lowering confuses
            # single-element tuples with actual single elements, which
            # is why single-element tuples do not get considered by MLIR
            # as a composite return.
            # This confusion exists at the MLIR builtin language level and
            # there's nothing we can do about it.
            if issubclass(f.return_type, Tuple):
                retval_ct = (retval_ct,)

            return self.val_from_CType(f.return_type, retval_ct)

        # instantiate a structure return type, which by LLVM calling
        # convention is a void function that writes the return value in-place
        # to the first argument
        retval = CTypeTreeType_to_Structure(self.get_return_ctypes(f))()
        mapped_args.insert(0, retval)

        so_f(*mapped_args)  # Call function

        # the result is written in-place to retval. Convert it back to Python
        # CTypes
        retval_ct = CTypeTree_from_Structure(self.get_return_ctypes(f), retval)

        return self.val_from_CType(f.return_type, retval_ct)

    def get_supported_dialects(self) -> set[Dialect]:
        extra_supported = {Dialect.from_name("transform.validator")}
        return (
            super().get_supported_dialects(extra_supported) | extra_supported
        )


class MLIRTarget(CTarget):
    @property
    def _flags(self: Self) -> list[str]:
        return []

    def build(self) -> None:
        mlir = self.emit_mlir()

        file = NamedTemporaryFile(dir=self.binpath, suffix=".mlir")

        with open(file.name, "w") as f:
            f.write(mlir)

        self.mlir_passes(Path(file.name), self._flags)

    def mlir_passes(self, src: Path, flags, cmd="mlir-opt"):
        if self.settings.dump_mlir_passes:
            flags.append("-mlir-print-ir-before-all")

        self.run_and_pipe_output([cmd, *flags, src], None)


def create_MLIRTarget(passes: list[str], base_class=MLIRTarget):
    @property
    def _flags(self: Self) -> list[str]:
        return passes

    subclass = type("CustomMLIRTarget", (base_class,), {"_flags": _flags})
    return subclass


@dataclasses.dataclass
class CompilationSetting:
    # TODO: complete CompilationSetting documentation here
    transform_seq: Optional[Callable[[Any], None]] = None
    """
    The function object which will be compiled as the transform sequence of
    the module being compiled.

    Note: Pass the function in directly. Don't pass in the name of the function
    as a string.
    """

    dump_mlir: bool = False
    """
    Whether or not to log the resulting MLIR program (prior to any lowering)
    during compilation.
    """

    dump_mlir_passes: bool = False
    """
    Whether or not for `mlir-opt` to log the IR between each pass performed.

    This is equivalent to passing `-mlir-print-ir-before-all` to `mlir-opt`.
    """

    dump_llvmir: bool = False
    """
    Whether or not to log the resulting LLVM IR program during compilation.
    """

    auto_build: bool = True
    """
    Whether or not to try and build the output MLIR into a runnable binary as
    soon as it is compiled.
    """

    clean_temp: bool = False
    """
    Whether or not to clean up all the compilation artifacts after the Python
    program exits.
    """

    target_class: type["CompilationTarget"] = CTarget
    """
    The CompilationTarget which performs the compilation. The choice of class
    depends on your target output representation.
    """

    locals: dict[str, Any] = dataclasses.field(default_factory=dict)
    """
    A dictionary of variable names mapping to Python values. This will be used
    as the initial variable frame
    """

    dataset: str = "DEFAULT_DATASET"
    """
    An argument specific to target_class=PolyCTarget.
    This determines the input dataset which the output Polybench program will
    accept.
    """

    catch_comp_error: bool = True
    """
    Whether or not for the compiler to catch internal exceptions and
    pretty-print it in a manner friendly to language user.

    If True, all exceptions encountered during compilation will be caught and
    re-raised wrapped in a CompilationError exception. This will include
    information such as line-column number of the exception.

    Turning this option off is usually desirable for compiler debugging
    purposes as it destroys the exception stack trace up to the ToMLIR visitor.
    """

    override_fields: bool = True
    """
    Whether or not for a compiled object corresponding to an MLIR module to
    override `__getattribute__` with members of the module.

    This setting is mainly for debugging purposes and to allow users to
    access internal information about the module.
    """

    body_func: str = "__init__"
    """
    The name of the function in a module which is used to define module-level
    operators and variables.

    This setting is ignored if the function is not found.
    """

    log_level: int = logging.WARNING
    """
    The log level of the compilation process. This accepts any warning level
    constants in the `logging` standard library, such as `logging.WARNING`.
    """

    def apply(self):
        logging.basicConfig(level=self.log_level)


ObjectType = typing.TypeVar("ObjectType")


class CompiledObject(typing.Generic[ObjectType], ABC):
    _o: ObjectType
    _settings: CompilationSetting
    _target: CompilationTarget

    def __init__(
        self,
        o: ObjectType,
        locals: dict[str, Any],
        settings=CompilationSetting(),
    ) -> None:
        self._o = o
        self._settings = settings
        self._settings.locals = locals
        self._target = self._settings.target_class(
            src=self.get_src(),
            settings=self._settings,
        )

    @property
    def src_str(self) -> str:
        return textwrap.dedent(inspect.getsource(self._o))

    @property
    def src_ast(self) -> AST:
        return ast.parse(self.src_str)

    @property
    def filepath(self) -> Path:
        return Path(inspect.getsourcefile(self._o))

    @property
    def lineno(self) -> int:
        return inspect.getsourcelines(self._o)[1]

    @cache
    def get_src(self) -> Source:
        return Source.init_embeded(
            src_str=self.src_str,
            filepath=self.filepath,
            lineno=self.lineno,
        )

    def emit_mlir(self) -> str:
        return self._target.emit_mlir()


class CompiledFunction(CompiledObject[Callable[..., Any]]):
    def __call__(self, *args, **kwargs) -> Any:
        return self._target.call_function(self._o.__name__, *args, **kwargs)


class CompiledClass(CompiledObject[type]):
    finalized: bool = False

    def __init__(
        self,
        o: ObjectType,
        locals: dict[str, Any],
        settings=CompilationSetting(),
    ) -> None:
        super().__init__(o, locals, settings)
        self.finalize()

    @property
    def src_ast(self) -> ast.Module:
        src = super().src_ast
        self.dissolve_class(src)
        self.eliminate_body_func(src, self._settings.body_func)
        return src

    @staticmethod
    def dissolve_class(module: ast.Module) -> None:
        """
        Turns `module` of form ::

            Module(body=[ClassDef(body=cbody)])

        Into ::

            Module(body=cbody)
        """
        if (len(module.body) != 1) or (
            not isinstance(module.body[0], ast.ClassDef)
        ):
            raise ValueError(
                "CompiledClass did not recieve a single class definition as "
                "the source"
            )

        module.body = module.body[0].body

    @staticmethod
    def eliminate_body_func(module: ast.Module, body_func_name: str) -> None:
        """
        Turns `module` of form ::

            Module(body=[*nodesl, FunctionDef(name=body_func_name, body=bbody), *nodesr])

        Into ::

            Module(body=[*bbody, *nodesl, *nodesr])
        """
        for n in module.body:
            match n:
                case ast.FunctionDef(name=name, body=bbody) if (
                    name == body_func_name
                ):
                    module.body.remove(n)
                    module.body = [*bbody, *module.body]

    def __getattribute__(self, name):
        # NOTE: We can no longer use self.**** because that's overloaded with
        # this function. Doing so will result in recursion.
        # Use selfattr(****) instead!
        def selfattr(name: str):
            return object.__getattribute__(self, name)

        if not selfattr("finalized"):
            # Perform attributes as normal
            return selfattr(name)

        # Perform attributes as if we're the MLIR module
        return selfattr("get_module_attr")(name)

    def get_module_attr(self, name):
        """
        Get an attribute of the compiled MLIR module
        """

        # NOTE: We can no longer use self.**** because that's overloaded with
        # __getattribute__. Doing so will result in recursion.
        # Use selfattr(****) instead!
        def selfattr(name: str):
            return object.__getattribute__(self, name)

        _target = selfattr("_target")

        if name in _target.funcs():

            def make_call(*args, **kwargs) -> Any:
                return _target.call_function(name, *args, **kwargs)

            return make_call

        # Resort to default behavior if a magic method is invoked.
        if re.fullmatch("__.*__", name) is not None:
            return selfattr(name)

        raise AttributeError(
            f"attribute {name} is not found or is not accessible after "
            f"compilation in CompiledClass"
        )

    @cache
    def get_src(self) -> Source:
        return Source.init_embeded(
            src_str=self.src_str,
            src_ast=self.src_ast,
            filepath=self.filepath,
            lineno=self.lineno,
        )

    def finalize(self) -> None:
        """
        Override all attributes of this class with attributes of the compiled
        MLIR module, which would render all of CompiledClass' methods
        inaccessible except with `object.__getattribute__(self, attr)`.

        This function does nothing if the compilation setting
        `override_fields` = `False`
        """
        if self._settings.override_fields:
            self.finalized = True


def compile(
    context: typing.Optional[dict[str, Any]] = None,
    **settings,
) -> Callable[..., CompiledFunction]:
    """
    Compile a Python object with embedded PyDSL code into MLIR and lower it
    to a temporary shared library object.

    The lowered function is a CompiledFunction object which may be called
    directly to run the respective function in the library.

    Refer to `CompilationSetting` for a full list of keyword arguments
    passable to settings.

    While the compile decorator will try its best to determine what variables
    you need when f_vars is not provided, it cannot determine everything.
    It will try to include globals(), builtin variables, and locals(), but
    free variables in outer nested functions from where the decorated function
    is defined cannot be attained.
    This is an API gap of Python's metaprogramming features and
    nothing can be done about it:
    https://stackoverflow.com/questions/1041639/get-a-dict-of-all-variables-currently-in-scope-and-their-values.

    context: a dictionary of local variables you want the function to have
    access to. Typically passing in Python's built-in `locals()` is sufficient.

    See CompilationSetting for the full list of keyword arguments you can pass.
    """

    settings = CompilationSetting(**settings)
    settings.apply()

    if context is None:
        # Get the frame that called this function.
        f_back = inspect.currentframe().f_back

        """
        Make a dictionary starting with builtins, then update it with
        globals, then update it with locals of the last calling frame.

        This is also known as a dictionary union:
        https://peps.python.org/pep-0584/.
        """
        context = f_back.f_builtins | f_back.f_globals | f_back.f_locals

    @singledispatch
    def payload(f: Callable | type) -> CompiledObject: ...

    @payload.register
    def _(f: Callable) -> CompiledFunction:
        cf = CompiledFunction(
            f,
            context,
            settings,
        )

        return cf

    @payload.register
    def _(m: type) -> CompiledClass:
        cm = CompiledClass(
            m,
            context,
            settings,
        )

        return cm

    return payload


class Template:
    """
    A class which supports compilation using type parameters
    provided by the user. It works by deferring compilation until
    type parameters are known.

    This class holds a python function and all the information required
    to compile it when the type arguments are known.

    When subscripted with type arguments, the function is compiled with
    the parameters substituted for the type arguments in the context.
    """

    _f: Callable
    _tparams: list[ast.TypeVar]
    _context: typing.Optional[dict[str, Any]]
    _settings: dict

    def __init__(
        self,
        f: Callable,
        tparams: list[ast.TypeVar],
        context: typing.Optional[dict[str, Any]],
        settings: dict,
    ):
        self._f = f
        self._tparams = tparams
        self._context = context
        self._settings = settings

    @cache
    def __call__(self, *args, **kwargs):
        if self._tparams:
            raise NotImplementedError(
                "type inference for templates not yet implemented"
            )

        return compile(self._context, **self._settings)(self._f)(
            *args, **kwargs
        )

    @cache
    def __getitem__(self, template_args):
        if not isinstance(template_args, tuple):
            template_args = (template_args,)

        if len(template_args) != len(self._tparams):
            raise TypeError("incorrect number of template arguments")

        for ta, tp in zip(template_args, self._tparams):
            self._context[tp.name] = ta

        return compile(self._context, **self._settings)(self._f)


def template(context: typing.Optional[dict[str, Any]] = None, **settings):
    """
    A decorator which supports generic functions with type parameters.

    This decorator can be used instead of @compile on a PyDSL function,
    and it will allow the function to take template parameters in square
    brackets. Any arguments passed to the decorator itself will be
    forwarded to @compile.

    The general syntax is as follows:
    ```
    @template(...) # same arguments are compile
    def my_func[T, ...](a: T, ...): # T, ... is a list of template parameters
        ... # do stuff

    my_func[SInt32, ...](3, ...) # compilation occurs here
    ```

    For example
    @template()
    def my_func[T](a: T) -> T:
        return a

    my_func[SInt32](3) # returns 3
    my_func[F32](3.5) # return 3.5
    """
    if context is None:
        f_back = inspect.currentframe().f_back
        context = f_back.f_builtins | f_back.f_globals | f_back.f_locals

    def payload(f: Callable) -> CompiledFunction:
        func_ast: AST = ast.parse(textwrap.dedent(inspect.getsource(f)))

        assert isinstance(func_ast, ast.Module)
        func_ast = func_ast.body[0]
        if not isinstance(func_ast, ast.FunctionDef):
            raise NotImplementedError(
                "right now, templates only support functions, not classes"
            )

        return Template(f, func_ast.type_params, context, settings)

    return payload
